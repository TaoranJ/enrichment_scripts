# -*- coding: utf-8 -*-

"""

This module decodes the spacy enrichment content.

Enichment contents supported are listes as follow:

    1. Tokenization and lemmatization.
    2. Dependency strucutre.
    3. Svos.
    4. Named entities.
    5. Noun chunks.

"""

import spacy

if spacy.__version__ == '1.9.0':  # much faster
    from spacy.en.word_sets import STOP_WORDS
else:
    from spacy.lang.en.stop_words import STOP_WORDS

IGNORE_POS = ['PUNCT', 'SYM', 'NUM']
"""A default list of POS to ignore."""


class SpacyEnrichmentReader(object):
    """

    Class handling spacy_enrichment field generated by SpacyEnrichment.

    ::

       metadata['spacy_enrichment'] = {
           'token' : [
               {},
               ...],
           'noun_chunks' : [noun chunks],
           'svos' : [vo : s],
           'named_entities' : [named entities]
       }

    """

    @classmethod
    def _get_spacy_enrichment_content(cls, record):
        """Get content of spacy enrichment for this record.

        Parameters
        ----------
        record : str
            Plain text of record in JSON format.

        Raises
        ------
        ValueError
            Raise if the record is in bad JSON format.

        Returns
        -------
        dict
            Record in dict.

        """

        return record.get('spacy_enrichment', {})

    @classmethod
    def get_tokens(cls, record):
        """Get tokens information along with its POS, lemma.

        Parameters
        ----------
        record : str
            Plain text of record in JSON format.

        Returns
        -------
        list
            List of tokens information.

        """

        return cls._get_spacy_enrichment_content(record).get('token', [])

    @classmethod
    def get_named_entities(cls, record):
        """Get named entities in this record

        Parameters
        ----------
        record : str
            Plain text of record in JSON format.

        Returns
        -------
        list
            List of named entities.

        """

        return cls._get_spacy_enrichment_content(record).get(
                'named_entities', [])

    @classmethod
    def get_noun_chunks(cls, record):
        """Get nont chunks in this record.

        Parameters
        ----------
        record : str
            Plain text of record in JSON format.

        Returns
        -------
        list
            List of noun chunks.

        """
        return cls._get_spacy_enrichment_content(record).get('noun_chunks', [])

    @classmethod
    def get_svos(cls, record):
        """Get SVOs (subject-verb-object) in this record.

        Parameters
        ----------
        record : str
            Plain text of record in JSON format.

        Returns
        -------
        list
            List of SVOs.

        """
        return cls._get_spacy_enrichment_content(record).get('svos', [])

    @classmethod
    def get_lemmas(cls, record, ingore_pos=IGNORE_POS, min_length=3,
                   stopwords=STOP_WORDS):
        """Get lemma of each token.

        Parameters
        ----------
        record : str
            Plain text of record in JSON format.
        ignore_pos : list
            Drop tokens which has a POS tag in this list.
        min_length : int
            Drop lemma whose length is less than this value.
        stopwords : list
            List of stop words.

        Returns
        -------
        list
            A list of lemmas in this record.

        """

        return [token['lemma'] for token in cls.get_tokens(record)
                if token['lemma'] and token['lemma'] not in stopwords
                and token['pos'] not in ingore_pos
                and len(token['lemma']) >= min_length]

    @classmethod
    def get_doc_content_in_lemma(cls, record):
        """Get lemmatized doc content.

        Parameters
        ----------
        record : dict
            Content and metadata of a record in dict data structure.

        Returns
        -------
        list
            List of lemmas of content of record ordered in original format.

        """

        return [token['lemma']
                for token in
                sorted(cls.get_tokens(record), key=lambda x:x['index'])]

    @classmethod
    def get_term_counts(cls, record, terms):
        """Count term (can be n-grams) frequency in the lemma form doc content.

        Note
        ----
        Here the count is based on the number of non overlapping matches.

        Parameters
        ----------
        record : dict
            Content and metadata of a record in dict data structure.
        terms : list
            List of terms to calculate term frequency.

        Returns
        -------
        dict
            {term : term frequency}
        """

        lemmas = ' '.join(cls.get_doc_content_in_lemma(record))
        return {term: lemmas.count(term) for term in terms}

    @classmethod
    def get_term_counts_linguistic(cls, record, terms):
        pass
